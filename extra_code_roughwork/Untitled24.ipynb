{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaeeyMZ13ybm",
        "outputId": "877b14e2-f4f9-4beb-9a44-941dc95a4ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-02 01:57:12--  https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.207, 64.233.187.207, 64.233.188.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109540975 (104M) [application/zip]\n",
            "Saving to: ‘pizza_steak.zip’\n",
            "\n",
            "pizza_steak.zip     100%[===================>] 104.47M  26.7MB/s    in 4.9s    \n",
            "\n",
            "2023-11-02 01:57:17 (21.3 MB/s) - ‘pizza_steak.zip’ saved [109540975/109540975]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Download zip file of pizza_steak images\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4KEaahFbAAv",
        "outputId": "a7a9ff15-a8db-4fe6-dfdd-f03d73abe486"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 'pizza_steak'.\n",
            "There are 2 directories and 0 images in 'pizza_steak/test'.\n",
            "There are 0 directories and 250 images in 'pizza_steak/test/steak'.\n",
            "There are 0 directories and 250 images in 'pizza_steak/test/pizza'.\n",
            "There are 2 directories and 0 images in 'pizza_steak/train'.\n",
            "There are 0 directories and 750 images in 'pizza_steak/train/steak'.\n",
            "There are 0 directories and 750 images in 'pizza_steak/train/pizza'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "\n",
        "num_steak_images_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2QMJbD2bfVh",
        "outputId": "1cd21378-0c4c-48a0-93a4-6caa4a152e13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names (programmatically, this is much more helpful with a longer list of classes)\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(\"pizza_steak/train/\") # turn our training path into a Python path\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPTxKioMb9vv",
        "outputId": "c40d64a8-b626-40d9-c470-e572877b86ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pizza' 'steak']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  # Setup target directory (we'll view images from here)\n",
        "  target_folder = target_dir+target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "\n",
        "  # Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
        "\n",
        "  return img\n"
      ],
      "metadata": {
        "id": "FaBq5irIcmFh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = view_random_image(target_dir=\"pizza_steak/train/\",\n",
        "                        target_class=\"steak\")"
      ],
      "metadata": {
        "id": "9JYIQArade5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.constant(img)"
      ],
      "metadata": {
        "id": "nV_Pm2SKd82q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape # width, height, colour channels"
      ],
      "metadata": {
        "id": "zImlkB1nelUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the balue in 0 & 1\n",
        "img / 255."
      ],
      "metadata": {
        "id": "UWHnrB5neyTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# set a path from our current directories\n",
        "train_dir = \"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\"\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size = (244,244),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(directory=test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size = (244,244),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                               batch_size=32, # number of images to process at a time\n",
        "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
        "                                               class_mode=\"binary\", # type of problem we're working on\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(directory=test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "\n",
        "\n",
        "# build cnn model\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=10, kernel_size=3,\n",
        "                           activation='relu',\n",
        "                           input_shape=(224,224,3)),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, padding=\"valid\"),\n",
        "    tf.keras.layers.Conv2D(10,3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(10,3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# label and data created for us using flow_from_directory\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data), # total img / batch_size = total steps for machine to know and memory calculation for storing\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXCvTfuKfwY9",
        "outputId": "5e58808b-ccc2-4e5d-b4a4-3feaa09c24ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1500 images belonging to 2 classes.\n",
            "Found 500 images belonging to 2 classes.\n",
            "Found 1500 images belonging to 2 classes.\n",
            "Found 500 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "47/47 [==============================] - 19s 157ms/step - loss: 0.5900 - accuracy: 0.6793 - val_loss: 0.4407 - val_accuracy: 0.8040\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.4442 - accuracy: 0.8013 - val_loss: 0.3756 - val_accuracy: 0.8480\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.4148 - accuracy: 0.8140 - val_loss: 0.4109 - val_accuracy: 0.8080\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 6s 131ms/step - loss: 0.3672 - accuracy: 0.8540 - val_loss: 0.3199 - val_accuracy: 0.8840\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 5s 114ms/step - loss: 0.3183 - accuracy: 0.8667 - val_loss: 0.3415 - val_accuracy: 0.8540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update in tensorflow\n",
        "\n",
        "below you can see we have used ImageDataGenerator which has been updated to image_dataset_from_directory of tf.keras.utils.\n",
        "\n",
        "The main differences between them are:\n",
        "\n",
        "*   rescaling & data loading:\n",
        "    \n",
        "\n",
        "  1.   In `ImageDataGenerator` we rescaled imag then applied flow_from_directory, we used **target_size** and **class_mode**\n",
        "  2.   In `image_dataset_from_directory` we got the data from directory using **image_size** and **label_mode** which are used same as *target_size* and *class_mode*. here, to rescale image we have added new layer in Sequential Model:\n",
        "\n",
        "```\n",
        "tf.keras.layers.Rescaling(1./255,input_shape=(224,224,3)),\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LjMk6wBuzf0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# set a path from our current directories\n",
        "train_dir = \"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\"\n",
        "\n",
        "train_data = image_dataset_from_directory(directory=train_dir,\n",
        "                                               batch_size=32,\n",
        "                                               image_size = (224,224),\n",
        "                                               label_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = image_dataset_from_directory(directory=test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               image_size = (224,224),\n",
        "                                               label_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# build cnn model\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Rescaling(1./255,input_shape=(224,224,3)),\n",
        "    tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, padding=\"valid\"),\n",
        "    tf.keras.layers.Conv2D(10,3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(10,3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# label and data created for us using flow_from_directory\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data), # total img / batch_size = total steps for machine to know and memory calculation for storing\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfikyhiywS6S",
        "outputId": "5edeab16-28b1-4095-be6d-b4736c7a3d4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1500 files belonging to 2 classes.\n",
            "Found 500 files belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "47/47 [==============================] - 5s 81ms/step - loss: 0.6359 - accuracy: 0.6173 - val_loss: 0.4454 - val_accuracy: 0.8180\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 5s 95ms/step - loss: 0.4556 - accuracy: 0.7980 - val_loss: 0.4481 - val_accuracy: 0.8020\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 4s 74ms/step - loss: 0.4090 - accuracy: 0.8213 - val_loss: 0.3351 - val_accuracy: 0.8600\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 4s 72ms/step - loss: 0.3708 - accuracy: 0.8480 - val_loss: 0.3151 - val_accuracy: 0.8820\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 5s 88ms/step - loss: 0.3423 - accuracy: 0.8527 - val_loss: 0.3156 - val_accuracy: 0.8580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6dtxWl7WnZWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}